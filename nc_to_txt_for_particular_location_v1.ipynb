{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import netCDF4\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import calendar\n",
    "from datetime import datetime, timedelta,date\n",
    "from tqdm import tqdm\n",
    "import cftime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_KEYWORDS = {'0':[\"pr\",\"MOHC-HadGEM2-ES\",\"historical\"],\n",
    "            '1':[\"pr\",\"MOHC-HadGEM2-ES\",\"rcp85\"],\n",
    "            '2':[\"tas\",\"MOHC-HadGEM2-ES\",\"historical\"],\n",
    "            '3':[\"tas\",\"MOHC-HadGEM2-ES\",\"rcp85\"],\n",
    "            '4':[\"pr\",\"MPI-M-MPI-ESM-LR\",\"historical\"],\n",
    "            '5':[\"pr\",\"MPI-M-MPI-ESM-LR\",\"rcp85\"],\n",
    "            '6':[\"tas\",\"MPI-M-MPI-ESM-LR\",\"historical\"],\n",
    "            '7':[\"tas\",\"MPI-M-MPI-ESM-LR\",\"rcp85\"]}\n",
    "\n",
    "MY_ROOT=pathlib.Path(\"EAS-22\")\n",
    "\n",
    "# Target lat and lon\n",
    "# [For most of the domain, CORDEX data is based on rotated latitude and longitude, so we need to convert the coordinates of target location to rotated lat and lon]\n",
    "# Go to this website: https://agrimetsoft.com/Cordex%20Coordinate%20Rotation\n",
    "MY_LAT = 3.91\n",
    "MY_LON = -30.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_file_paths(root):\n",
    "\n",
    "    '''\n",
    "    Args: Parent directory where all the folder are located.\n",
    "    Purpose: To extract paths for all files.\n",
    "    Requirment: Need to have folder in tree format.\n",
    "    '''\n",
    "    file_path_collection = []\n",
    "    for climatic_var in root.iterdir():\n",
    "        if climatic_var.is_dir():\n",
    "            for model in climatic_var.iterdir():\n",
    "                if model.is_dir():\n",
    "                    for scenario in model.iterdir():\n",
    "                        if scenario.is_dir():\n",
    "                            for file in scenario.iterdir():\n",
    "                                file_path_collection.append(file)\n",
    "    return file_path_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nc_to_txt_specific_location(root,file_path_collection,file_keywords,lat,lon):\n",
    "    '''\n",
    "    Purpose: To extract data with specific attributes as denoted by keywords for specific coordinates as specified by users from netcdf file collection as indicated by file_path_collection\n",
    "    '''\n",
    "\n",
    "    filtered_paths = [file for file in file_path_collection if all(keyword in str(file) for keyword in file_keywords)]\n",
    "    #filtered_paths = generate_file_paths()\n",
    "\n",
    "    to_excel_df = pd.DataFrame()\n",
    "\n",
    "    for a_path in filtered_paths:\n",
    "        whole_nc = xr.open_dataset(a_path)\n",
    "        target_nc = whole_nc.sel(rlat = lat, rlon = lon, method='nearest')\n",
    "        nc_dates = target_nc['time'].values\n",
    "        Dates =[]\n",
    "        VariableValues = []\n",
    "        #standard_dates = [datetime.utcfromtimestamp(cft_date.timestamp()) for cft_date in cft_dates]\n",
    "        if all(isinstance(dt, cftime.Datetime360Day) for dt in nc_dates):\n",
    "            '''\n",
    "            This branch was necessary because one climate model data has the date in \"Datetime360Day\" format.\n",
    "            So, this will convert date format from this format to regular format.\n",
    "            '''\n",
    "            days = [date.day for date in nc_dates]\n",
    "            months = [date.month for date in nc_dates]\n",
    "            years = [date.year for date in nc_dates]\n",
    "            if file_keywords[0] == 'pr':\n",
    "                climatic_variable = target_nc[file_keywords[0]].values *86400\n",
    "            elif file_keywords[0] == 'tas':\n",
    "                climatic_variable = target_nc[file_keywords[0]].values-273.15\n",
    "            else:\n",
    "                print('Error! Please select appropriate climatic variable')\n",
    "\n",
    "            for year,month, day, val  in zip(years,months,days,climatic_variable):\n",
    "                last_day_of_month = calendar.monthrange(year,month)[1]\n",
    "                if day <= last_day_of_month:\n",
    "                    Dates.append(date(year,month,day))\n",
    "                    VariableValues.append(val)\n",
    "\n",
    "        else:\n",
    "            '''\n",
    "            This branch was necessary because one climate model data has the date in \"datetime64\" format. This is regular format, so\n",
    "            no necessary to preprocess before saving in dataframe.\n",
    "            '''\n",
    "            Dates = nc_dates\n",
    "            if file_keywords[0] == 'pr':\n",
    "                VariableValues = target_nc[file_keywords[0]].values *86400\n",
    "            elif file_keywords[0] == 'tas':\n",
    "                VariableValues = target_nc[file_keywords[0]].values-273.15\n",
    "            else:\n",
    "                print('Error! Please select appropriate climatic variable')\n",
    "   \n",
    "\n",
    "\n",
    "        temp_df = pd.DataFrame({'Date': Dates,'Climate Variable': VariableValues})\n",
    "        to_excel_df = pd.concat([to_excel_df,temp_df]\n",
    "                                ,axis=0)\n",
    "    to_excel_df.to_csv(f\"{root}/{file_keywords[0]}_{file_keywords[1]}_{file_keywords[2]}.txt\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:   0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Files relevant to ['pr', 'MOHC-HadGEM2-ES', 'historical'] being extracted to text format for Latitde:3.91, Longitude:-30.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  12%|█▎        | 1/8 [00:59<06:53, 59.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Files relevant to ['pr', 'MOHC-HadGEM2-ES', 'rcp85'] being extracted to text format for Latitde:3.91, Longitude:-30.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  25%|██▌       | 2/8 [03:44<12:08, 121.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Files relevant to ['tas', 'MOHC-HadGEM2-ES', 'historical'] being extracted to text format for Latitde:3.91, Longitude:-30.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  38%|███▊      | 3/8 [04:23<06:59, 83.87s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Files relevant to ['tas', 'MOHC-HadGEM2-ES', 'rcp85'] being extracted to text format for Latitde:3.91, Longitude:-30.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  50%|█████     | 4/8 [06:16<06:22, 95.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Files relevant to ['pr', 'MPI-M-MPI-ESM-LR', 'historical'] being extracted to text format for Latitde:3.91, Longitude:-30.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  62%|██████▎   | 5/8 [07:11<04:02, 80.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Files relevant to ['pr', 'MPI-M-MPI-ESM-LR', 'rcp85'] being extracted to text format for Latitde:3.91, Longitude:-30.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  75%|███████▌  | 6/8 [09:55<03:38, 109.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Files relevant to ['tas', 'MPI-M-MPI-ESM-LR', 'historical'] being extracted to text format for Latitde:3.91, Longitude:-30.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  88%|████████▊ | 7/8 [10:34<01:26, 86.21s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Files relevant to ['tas', 'MPI-M-MPI-ESM-LR', 'rcp85'] being extracted to text format for Latitde:3.91, Longitude:-30.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 8/8 [12:20<00:00, 92.54s/it]\n"
     ]
    }
   ],
   "source": [
    "file_path_collection = generate_file_paths(root=MY_ROOT)\n",
    "for i in tqdm(range(len(MY_KEYWORDS)),desc='Processing files'):\n",
    "    print(f\" Files relevant to {MY_KEYWORDS[str(i)]} being extracted to text format for Latitde:{MY_LAT}, Longitude:{MY_LON}\")\n",
    "    nc_to_txt_specific_location(root=MY_ROOT,file_path_collection=file_path_collection,file_keywords=MY_KEYWORDS[str(i)],lat= MY_LAT, lon = MY_LON)\n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
